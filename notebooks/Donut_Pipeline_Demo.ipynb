{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Survey Plan AI - Donut Pipeline Demo\n",
                "\n",
                "This notebook demonstrates the modular 3-stage pipeline for parsing survey plans:\n",
                "1. **Detection**: YOLO + SAHI for object detection (Tables, Title Blocks, Bearings).\n",
                "2. **Bridge**: Rectification and cropping of oriented bounding boxes (OBB).\n",
                "3. **Parsing**: Donut model for extracting structured text from crops."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository (if running in Colab and not already cloned)\n",
                "!git clone https://github.com/14jadon14/survey-plan-AI.git\n",
                "%cd survey-plan-AI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add current directory to path to ensure modules are found\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "from src.pipeline import SurveyPipeline\n",
                "from src import config\n",
                "\n",
                "# Initialize the pipeline (Loads YOLO/SAHI and Donut models)\n",
                "pipeline = SurveyPipeline()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download a sample image if you don't have one\n",
                "# !wget -O sample_plan.jpg <URL_TO_SAMPLE_IMAGE>\n",
                "\n",
                "# Or use a dummy image for testing flow if no sample available\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "import cv2\n",
                "\n",
                "if not os.path.exists(\"sample_plan.jpg\"):\n",
                "    print(\"Creating dummy test image...\")\n",
                "    img = np.ones((2000, 2000, 3), dtype=np.uint8) * 255\n",
                "    # Draw some fake text/box\n",
                "    cv2.putText(img, \"Test Plan\", (500, 500), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
                "    cv2.imwrite(\"sample_plan.jpg\", img)\n",
                "\n",
                "image_path = \"sample_plan.jpg\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the pipeline\n",
                "results = pipeline.process_image(image_path)\n",
                "\n",
                "# Display Results\n",
                "import json\n",
                "\n",
                "print(f\"Processing complete for {results['image_path']}\")\n",
                "print(f\"Found {len(results['detections'])} objects.\")\n",
                "\n",
                "# Pretty print first few detections\n",
                "for i, det in enumerate(results['detections'][:5]):\n",
                "    print(f\"\\nObject {i+1}: {det['label']} ({det['confidence']:.2f})\")\n",
                "    print(f\"Parsed Data: {det['parsed_data']}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}